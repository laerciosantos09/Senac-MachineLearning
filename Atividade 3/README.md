# Respostas dos Exerc√≠cios de Regress√£o Linear

## üë§ Autor

**La√©rcio Santos**

P√≥s-gradua√ß√£o em Intelig√™ncia Artificial - Centro Universit√°rio SENAC


## üöÄ Executar no Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%203/RespostasAtividade3.ipynb)

**Link direto:** [Abrir no Google Colab](https://colab.research.google.com/github/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%203/RespostasAtividade3.ipynb)




## Exerc√≠cio 1
**Para cada um dos conjuntos de treinamento, utilize a fun√ß√£o fit m√∫ltiplas vezes considerando apenas um atributo preditor.**

### 1. O modelo aprendido muda a cada vez que a fun√ß√£o fit √© utilizada?
* **LinearRegression (OLS):** **N√£o.** O m√©todo dos M√≠nimos Quadrados Ordin√°rios √© uma solu√ß√£o anal√≠tica fechada (determin√≠stica). Dado o mesmo conjunto de dados, ele sempre calcular√° exatamente os mesmos coeficientes e intercepto.
* **SGDRegressor:** **Sim.** Como este algoritmo utiliza Descida de Gradiente Estoc√°stica, ele inicia com pesos aleat√≥rios e atualiza os pesos iterativamente. Se o par√¢metro `random_state` n√£o for fixado, o caminho de otimiza√ß√£o varia ligeiramente a cada execu√ß√£o, resultando em modelos finais levemente diferentes.

### 2. Os modelos finais aprendidos s√£o os mesmos da outra implementa√ß√£o de regress√£o linear?
**R:** Eles s√£o **muito pr√≥ximos**, mas n√£o id√™nticos.
* A `LinearRegression` encontra o valor √≥timo exato global.
* O `SGDRegressor` encontra uma aproxima√ß√£o desse valor. Com n√∫mero suficiente de itera√ß√µes e dados normalizados, o SGD converge para valores extremamente pr√≥ximos aos da regress√£o linear cl√°ssica.

---

## Exerc√≠cio 2
**Aprenda modelos utilizando todos os atributos de entrada.**

### 1. Baseado no RSS e no R^2, √© poss√≠vel obter um modelo melhor utilizando todos os dados?
**R: Sim.**
* Ao utilizar as tr√™s vari√°veis (TV, Radio, Newspaper), o $R^2$ sobe para aproximadamente **0.897** (explicando quase 90% da vari√¢ncia das vendas).
* Comparativamente, modelos com apenas uma vari√°vel (ex: apenas TV) costumam ter um $R^2$ bem menor (em torno de 0.61). Adicionar informa√ß√µes relevantes diminui o RSS (erro residual) e melhora o ajuste.

### 2. Existem atributos que poderiam ser desconsiderados sem que fosse afetada a precis√£o?
**R: Sim, o atributo "Newspaper".**
* Ao analisar os coeficientes ou remover a vari√°vel, observa-se que o $R^2$ praticamente n√£o se altera (cai de ~0.8972 para ~0.8971). Isso sugere que o investimento em jornal n√£o traz poder preditivo adicional significativo quando j√° sabemos o investimento em TV e R√°dio.

### 3. Qual implementa√ß√£o treina mais r√°pido? A com m√©todo dos m√≠nimos quadrados ou a com descida de gradiente?
**R:** Para bases de dados pequenas como esta (*Advertising* tem 200 linhas), o **M√©todo dos M√≠nimos Quadrados (`LinearRegression`)** √© mais r√°pido.
* A descida de gradiente (`SGDRegressor`) √© vantajosa computacionalmente apenas quando o n√∫mero de dados √© massivo (milh√µes de exemplos), onde a invers√£o de matrizes do m√©todo cl√°ssico se torna invi√°vel.

---

## Exerc√≠cio 3
**Realizar a an√°lise da qualidade dos preditores utilizados no modelo constru√≠do.**

### 1. Construir o plot de res√≠duos. Ser√° que os res√≠duos est√£o aleatoriamente distribu√≠dos ao redor de 0?
![Plot de Res√≠duos](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%203/plot_residuos.png)](https://github.com/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%203/plot_residuos.png)
[![Exerc√≠cio 1 - Compara√ß√£o Tamanho vs Quartos]
(https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/ex1_comparacao.png)]


**R:** Os res√≠duos est√£o distribu√≠dos em torno de 0, o que √© bom, mas **n√£o s√£o perfeitamente aleat√≥rios**. No dataset *Advertising*, √© comum observar uma forma leve de "U" (curvatura) no gr√°fico de res√≠duos x preditos. Isso indica que, embora o modelo linear seja bom, ainda existe alguma n√£o-linearidade nos dados (intera√ß√£o entre TV e R√°dio) que o modelo linear simples n√£o capturou perfeitamente.

### 2. Calcular os valores p para os preditores. Comparar desempenho removendo vari√°veis.
**R:**
* **TV e Radio:** Possuem valores-p extremamente baixos (p < 0.000), indicando alta signific√¢ncia estat√≠stica.
* **Newspaper:** Possui um valor-p alto (geralmente acima de 0.05 ou at√© 0.8), indicando que n√£o √© estatisticamente significativo para o modelo na presen√ßa das outras vari√°veis.
* **Compara√ß√£o:** O modelo treinado apenas com **TV e Radio** (excluindo Newspaper) mant√©m praticamente o mesmo desempenho ($R^2 \approx 0.897$), confirmando que *Newspaper* √© redundante e pode ser removido para simplificar o modelo.

---

## Exerc√≠cio 4 (Extra)
**Realizar o teste para descobrir multicolinearidade entre vari√°veis preditivas (VIF).**

### 1. Existe alguma evid√™ncia de multicolinearidade entre as vari√°veis preditivas?
**R:** **N√£o h√° evid√™ncia de multicolinearidade severa.**
* Os valores de VIF (Variance Inflation Factor) para TV, Radio e Newspaper costumam ficar baixos (geralmente entre **1.0 e 1.5**).
* Como regra pr√°tica, preocupamo-nos com multicolinearidade quando o VIF excede 5 ou 10. Valores pr√≥ximos de 1 indicam que as vari√°veis s√£o independentes entre si, o que √© ideal para a regress√£o linear.
