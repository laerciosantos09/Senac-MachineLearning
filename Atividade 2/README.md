# Exerc√≠cios - Regress√£o Linear Univariada


## üë§ Autor

**La√©rcio Santos**

P√≥s-gradua√ß√£o em Intelig√™ncia Artificial - Centro Universit√°rio SENAC


## üöÄ Executar no Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/Solucao_Exercicios_Regressao_Linear.ipynb)

**Link direto:** [Abrir no Google Colab](https://colab.research.google.com/github/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/Solucao_Exercicios_Regressao_Linear.ipynb)

---

## üìÅ Fontes de Dados

| Dataset | Descri√ß√£o | Link |
|---------|-----------|------|
| **Portland House Prices** | Pre√ßos de casas com tamanho e n√∫mero de quartos (47 amostras) | [Portland_housePrices.csv](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/refs/heads/main/Atividade%202/Portland_housePrices.csv) |
| **Advertising** | Dados de publicidade (TV, Radio, Newspaper) e vendas (200 amostras) | [Advertising.csv](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/refs/heads/main/Atividade%202/Advertising.csv) |

---

# üìù EXERC√çCIO 1 - Pre√ßo de Casas (Portland)

**O Desafio:** Descobrir o que influencia mais no pre√ßo final de um im√≥vel: o **tamanho** (√°rea) ou o **n√∫mero de quartos**.

## Resultados Simplificados

| Atributo | Precis√£o do Modelo (R¬≤) | Margem de Erro (RSS) | Impacto no Pre√ßo |
|----------|-----|-----|-------------|
| **Tamanho** | **73% (Alta)** | **Menor Erro** | +$134 por p√©¬≤ |
| Quartos | 20% (Baixa) | Maior Erro | +$72.669 por quarto |

## Visualiza√ß√£o dos Modelos

[![Exerc√≠cio 1 - Compara√ß√£o Tamanho vs Quartos](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/ex1_comparacao.png)](https://github.com/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/ex1_comparacao.png)

---

## Respostas - Exerc√≠cio 1

### P1. Olhando o gr√°fico, qual caracter√≠stica faz mais sentido?

**Resposta:** O **TAMANHO** √© visualmente o vencedor.
* Note como os pontos (casas) seguem uma linha crescente bem definida: casa maior, pre√ßo maior.
* J√° no gr√°fico de quartos, os pontos est√£o muito espalhados. Existem casas com poucos quartos que s√£o caras e casas com muitos quartos que s√£o baratas, o que confunde o modelo.

### P2. O que aprendemos com cada caracter√≠stica?

**Resposta:**

**Com Tamanho (O Vencedor):**
* **Regra de Ouro:** Para cada unidade de espa√ßo a mais, o pre√ßo sobe cerca de **$134**.
* O modelo confia que **73%** da varia√ß√£o de pre√ßo vem do tamanho. √â uma aposta segura.

**Com Quartos (O Perdedor):**
* **Regra Fraca:** O modelo tenta dizer que cada quarto aumenta o pre√ßo em ~$72 mil, mas ele erra muito.
* Apenas **20%** do pre√ßo √© explicado pelos quartos. √â uma aposta arriscada.

### P3. Os n√∫meros confirmam o visual?

**Resposta:** **SIM**. Os n√∫meros comprovam o que vimos no gr√°fico.
* A precis√£o (R¬≤) do Tamanho √© quase **4 vezes maior** que a de Quartos.
* O erro acumulado (RSS) do Tamanho √© muito menor.
* **Conclus√£o:** Para avaliar uma casa nesta regi√£o, use a r√©gua, n√£o conte as portas.

---

# üìù EXERC√çCIO 2 - Investimento em Propaganda

**O Desafio:** Temos dados de vendas baseados em investimentos em TV, R√°dio e Jornal. Qual m√≠dia traz mais retorno e previsibilidade?

## Resultados Simplificados

| Atributo | Precis√£o (R¬≤) | Impacto nas Vendas | Classifica√ß√£o |
|----------|-----|-------------|---|
| **TV** | **61% (Boa)** | +47 vendas a cada $1k | ü•á O Melhor |
| Radio | 33% (M√©dia) | +202 vendas a cada $1k | ü•à Inst√°vel |
| Newspaper | 5% (P√©ssima) | +54 vendas a cada $1k | ü•â Irrelevante |

## Visualiza√ß√£o dos Modelos

[![Exerc√≠cio 2 - Compara√ß√£o TV, Radio e Newspaper](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/ex2_comparacao.png)](https://github.com/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/ex2_comparacao.png)

[![Exerc√≠cio 2 - Gr√°fico de Barras Comparativo](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/ex2_barras.png)](https://github.com/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/ex2_barras.png)

---

## Respostas - Exerc√≠cio 2

### P1. Olhando o gr√°fico, onde o dinheiro rende mais?

**Resposta:** Na **TV**.
* O gr√°fico da TV mostra uma "escada" clara: quanto mais se investe, mais se vende.
* O R√°dio tem muito ru√≠do (pontos espalhados).
* O Jornal parece uma nuvem aleat√≥ria, sem padr√£o nenhum.

### P2. O que aprendemos sobre cada m√≠dia?

**Resposta:**

* **TV (Seguran√ßa):** Explica **61%** das vendas. √â o investimento mais previs√≠vel.
* **R√°dio (Risco):** Explica **33%**. Parece dar muito retorno por d√≥lar investido, mas √© inst√°vel.
* **Jornal (Desperd√≠cio):** Explica apenas **5%**. Basicamente, anunciar no jornal n√£o garante venda nenhuma neste cen√°rio.

### P3. Qual √© o melhor modelo?

**Resposta:** O modelo baseado em **TV** √© o campe√£o.

**Ranking de Confiabilidade:**
1.  **TV:** Maior precis√£o, menor erro.
2.  **R√°dio:** Precis√£o mediana.
3.  **Jornal:** Precis√£o quase nula.

**Conclus√£o:** Se tiver verba para apenas um canal, aposte na TV.

---

# üìù EXERC√çCIO 3 - O Teste da "Decoreba" (Treino vs Teste)

**O Desafio:** Comparar dois "c√©rebros" artificiais (Regress√£o Linear e KNN) para ver quem realmente aprende e quem apenas decora os dados.

* **Regress√£o Linear:** Tenta tra√ßar uma reta simples (tend√™ncia).
* **KNN:** Tenta copiar os vizinhos mais pr√≥ximos.

## Resultados Obtidos

### Pre√ßo de Casas (Portland)

| Modelo | Nota no Estudo (Treino) | Nota na Prova (Teste) | Veredito |
|--------|---------------------|-----------|----------|
| **Regress√£o Linear** | 76% | **58%** | **Aprovado (Honesto)** |
| KNN (k=3) | 73% | 17% | Reprovado (Decoreba) |

### Propaganda (Advertising)

| Modelo | Nota no Estudo (Treino) | Nota na Prova (Teste) | Veredito |
|--------|---------------------|-----------|----------|
| **Regress√£o Linear** | 57% | **67%** | **Aprovado (Excelente)** |
| KNN (k=3) | 66% | 59% | Aprovado |

## Visualiza√ß√£o dos Resultados


[![Exerc√≠cio 3 - Compara√ß√£o R¬≤ por Modelo](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/ex3_comparacao_r2.png)](https://github.com/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/ex3_comparacao_r2.png)

[![Exerc√≠cio 3 - Treino vs Teste](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/ex3_treino_teste.png)](https://github.com/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/ex3_treino_teste.png)


---

## Respostas - Exerc√≠cio 3

### Diferen√ßa entre os "C√©rebros"

* **Regress√£o Linear (O Aluno Esfor√ßado):** Tenta entender a l√≥gica geral (a tend√™ncia). √â mais simples, mas mais robusto quando v√™ dados novos.
* **KNN (O Aluno que Cola):** Tenta adivinhar a resposta olhando para os exemplos vizinhos. Se ele "colar" de poucos vizinhos (k=3), ele acerta muito no treino, mas erra feio na prova real.

### Item 1. Por que separar Treino e Teste?

**Resposta:**

√â como separar o **livro de exerc√≠cios** da **prova final**.
* No caso das Casas em Portland, o modelo **KNN** foi desmascarado. Ele teve nota alta no treino (74%), mas tirou nota 18% na prova (Teste). Isso √© **Overfitting** (superajuste/decoreba).
* A **Regress√£o Linear** manteve notas mais pr√≥ximas, provando ser mais confi√°vel.

### Item 2. E se us√°ssemos todos os dados sem separar?

**Resposta:** Seria uma **ilus√£o**.
* O desempenho pareceria incr√≠vel (notas altas), mas seria falso.
* Estar√≠amos dando a prova com as mesmas perguntas que o aluno j√° viu.
* **Conclus√£o:** Sem separar dados de Teste, n√£o temos como saber se a IA vai funcionar no mundo real.

---

## üìä Resumo Final para Gestores

| Li√ß√£o | Explica√ß√£o |
|-----------|---------------------|
| **Tamanho Importa** | Para casas, √°rea constru√≠da √© o melhor indicador de pre√ßo. |
| **TV Vende** | Para este cliente, TV √© o investimento de marketing mais seguro. |
| **N√£o se Iluda** | Sempre exija testes com dados "novos" para validar qualquer IA. |
| **Simplicidade** | Muitas vezes, o modelo mais simples (Regress√£o Linear) bate o mais complexo. |

---

## üõ†Ô∏è Tecnologias Utilizadas

- Python 3
- Pandas & NumPy (C√°lculos)
- Matplotlib (Gr√°ficos)
- Scikit-learn (Intelig√™ncia Artificial)

---
