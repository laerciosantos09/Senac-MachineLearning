# ExercÃ­cios - RegressÃ£o Linear Univariada

## ğŸš€ Executar no Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/Solucao_Exercicios_Regressao_Linear.ipynb)

**Link direto:** [Abrir no Google Colab](https://colab.research.google.com/github/laerciosantos09/Senac-MachineLearning/blob/main/Atividade%202/Solucao_Exercicios_Regressao_Linear.ipynb)

---

## ğŸ“ Fontes de Dados

| Dataset | DescriÃ§Ã£o | Link |
|---------|-----------|------|
| **Portland House Prices** | PreÃ§os de casas com tamanho e nÃºmero de quartos (47 amostras) | [Portland_housePrices.csv](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/refs/heads/main/Atividade%202/Portland_housePrices.csv) |
| **Advertising** | Dados de publicidade (TV, Radio, Newspaper) e vendas (200 amostras) | [Advertising.csv](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/refs/heads/main/Atividade%202/Advertising.csv) |

---

# ğŸ“ EXERCÃCIO 1 - Portland House Prices

**Objetivo:** Treinar modelos lineares na base Portland_housePrices.csv utilizando apenas um dos atributos preditores.

## Resultados Obtidos

| Atributo | RÂ² | RSS | Coeficiente |
|----------|-----|-----|-------------|
| **Tamanho** | **0.7310** | **193,464,477,600.71** | 134.53 |
| Quartos | 0.1956 | 578,535,325,112.52 | 72,669.65 |

## VisualizaÃ§Ã£o dos Modelos

![ExercÃ­cio 1 - ComparaÃ§Ã£o Tamanho vs Quartos](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/images/ex1_comparacao.png)

![Minha Imagem](./imagens/ex1_comparacao.png)

---

## Respostas - ExercÃ­cio 1

### P1. Observando visualmente o modelo, qual atributo parece mais razoÃ¡vel?

**Resposta:** O atributo **TAMANHO** parece visualmente mais razoÃ¡vel porque:

- Os pontos de dados estÃ£o **mais prÃ³ximos da linha de regressÃ£o**
- HÃ¡ uma **relaÃ§Ã£o linear mais clara** e evidente entre tamanho e preÃ§o
- A **dispersÃ£o dos resÃ­duos Ã© menor** e mais uniforme ao redor da reta
- No grÃ¡fico de "Quartos vs PreÃ§o", os pontos estÃ£o muito dispersos verticalmente para cada valor de quarto, indicando que o nÃºmero de quartos sozinho nÃ£o explica bem a variaÃ§Ã£o no preÃ§o

### P2. O que foi aprendido com tamanho ou com nÃºmero de quartos?

**Resposta:**

**Com Tamanho:**
- **Coeficiente aprendido: 134.53** â†’ Para cada pÃ©Â² adicional, o preÃ§o aumenta aproximadamente $134,53
- O modelo aprendeu uma relaÃ§Ã£o forte e consistente: casas maiores custam mais
- RÂ² = 0.73 indica que **73% da variaÃ§Ã£o no preÃ§o Ã© explicada pelo tamanho**

**Com Quartos:**
- **Coeficiente aprendido: 72,669.65** â†’ Para cada quarto adicional, o preÃ§o aumenta aproximadamente $72,669
- O modelo aprendeu uma relaÃ§Ã£o fraca: mais quartos tendem a aumentar o preÃ§o, mas com muita variabilidade
- RÂ² = 0.20 indica que **apenas 20% da variaÃ§Ã£o no preÃ§o Ã© explicada pelo nÃºmero de quartos**
- O atributo "quartos" Ã© discreto (poucos valores Ãºnicos: 1-5), o que dificulta o ajuste linear

### P3. O RSS e RÂ² corroboram suas impressÃµes observando o modelo?

**Resposta:** **SIM**, as mÃ©tricas corroboram completamente a anÃ¡lise visual:

| MÃ©trica | Tamanho | Quartos | InterpretaÃ§Ã£o |
|---------|---------|---------|---------------|
| **RÂ²** | 0.7310 âœ… | 0.1956 | Tamanho explica ~3.7x mais variÃ¢ncia |
| **RSS** | 193 bi âœ… | 578 bi | Tamanho tem ~3x menos erro total |

- **RÂ² do Tamanho Ã© muito MAIOR (0.73 vs 0.20):** Confirma que o tamanho explica uma proporÃ§Ã£o significativamente maior da variÃ¢ncia do preÃ§o
- **RSS do Tamanho Ã© muito MENOR:** Confirma que as previsÃµes baseadas no tamanho sÃ£o muito mais precisas (menor soma dos erros quadrados)

**ConclusÃ£o:** O modelo com **TAMANHO** Ã© claramente superior ao modelo com **QUARTOS** para prever o preÃ§o das casas em Portland.

---

# ğŸ“ EXERCÃCIO 2 - Advertising

**Objetivo:** Treinar modelos lineares na base Advertising.csv utilizando apenas um dos atributos preditores.

## Resultados Obtidos

| Atributo | RÂ² | RSS | Coeficiente |
|----------|-----|-----|-------------|
| **TV** | **0.6119** | **2,102.53** | 0.0475 |
| Radio | 0.3320 | 3,618.48 | 0.2025 |
| Newspaper | 0.0521 | 5,134.80 | 0.0547 |

## VisualizaÃ§Ã£o dos Modelos

![ExercÃ­cio 2 - ComparaÃ§Ã£o TV, Radio e Newspaper](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/images/ex2_comparacao.png)

![ExercÃ­cio 2 - GrÃ¡fico de Barras Comparativo](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/images/ex2_barras.png)

---

## Respostas - ExercÃ­cio 2

### P1. Observando visualmente o modelo, qual atributo parece mais razoÃ¡vel?

**Resposta:** Visualmente, o atributo **TV** parece mais razoÃ¡vel porque:

- Os pontos seguem um **padrÃ£o linear mais claro** e definido
- A **dispersÃ£o ao redor da linha de regressÃ£o Ã© menor**
- HÃ¡ uma **tendÃªncia crescente mais evidente**: quanto maior o investimento em TV, maiores as vendas

**AnÃ¡lise visual dos trÃªs atributos:**
- **TV:** RelaÃ§Ã£o linear clara, pontos bem agrupados ao redor da reta
- **Radio:** Alguma relaÃ§Ã£o positiva visÃ­vel, mas com dispersÃ£o maior
- **Newspaper:** RelaÃ§Ã£o muito fraca, pontos extremamente dispersos, quase sem padrÃ£o linear

### P2. O que foi aprendido com TV, radio ou newspaper?

**Resposta:**

**Com TV:**
- **Coeficiente: 0.0475** â†’ Para cada $1.000 investidos em TV, as vendas aumentam ~47,5 unidades
- RÂ² = 0.61 â†’ **61% da variaÃ§Ã£o nas vendas Ã© explicada pelo investimento em TV**
- Aprendizado: TV tem **forte influÃªncia positiva** nas vendas

**Com Radio:**
- **Coeficiente: 0.2025** â†’ Para cada $1.000 investidos em Radio, as vendas aumentam ~202,5 unidades
- RÂ² = 0.33 â†’ **33% da variaÃ§Ã£o nas vendas Ã© explicada pelo investimento em Radio**
- Aprendizado: Radio tem **influÃªncia moderada** nas vendas
- Nota: O coeficiente maior nÃ£o significa melhor modelo - a variabilidade Ã© muito alta

**Com Newspaper:**
- **Coeficiente: 0.0547** â†’ Para cada $1.000 investidos em Newspaper, as vendas aumentam ~54,7 unidades
- RÂ² = 0.05 â†’ **Apenas 5% da variaÃ§Ã£o nas vendas Ã© explicada pelo investimento em Newspaper**
- Aprendizado: Newspaper tem **influÃªncia muito fraca/quase nula** nas vendas

### P3. Qual dos modelos Ã© melhor? Como vocÃª chegou a esta conclusÃ£o?

**Resposta:** O modelo com **TV** Ã© claramente o melhor.

**Metodologia utilizada para chegar a esta conclusÃ£o:**

1. **AnÃ¡lise do RÂ² (Coeficiente de DeterminaÃ§Ã£o):**
   - TV: RÂ² = 0.6119 â†’ **Melhor** (explica 61% da variÃ¢ncia)
   - Radio: RÂ² = 0.3320 â†’ IntermediÃ¡rio (explica 33%)
   - Newspaper: RÂ² = 0.0521 â†’ **Pior** (explica apenas 5%)

2. **AnÃ¡lise do RSS (Residual Sum of Squares):**
   - TV: RSS = 2,102 â†’ **Melhor** (menor erro total)
   - Radio: RSS = 3,618 â†’ IntermediÃ¡rio
   - Newspaper: RSS = 5,134 â†’ **Pior** (maior erro total)

3. **AnÃ¡lise Visual:**
   - TV apresenta os pontos mais prÃ³ximos da linha de regressÃ£o

**Ranking Final: TV > Radio > Newspaper**

**ConclusÃ£o:** Para prever vendas usando apenas um atributo, o investimento em **TV** Ã© o preditor mais confiÃ¡vel e preciso.

---

# ğŸ“ EXERCÃCIO 3 - ComparaÃ§Ã£o LR vs KNN com Train/Test Split

**Objetivo:** 
1. Comparar os resultados das duas regressÃµes com a implementaÃ§Ã£o do KNN-Regressor
2. Utilizar partiÃ§Ãµes de treino e teste para avaliar os modelos

## Resultados Obtidos

### Portland House Prices (Tamanho â†’ PreÃ§o)

| Modelo | RÂ² Dataset Completo | RÂ² Treino | RÂ² Teste |
|--------|---------------------|-----------|----------|
| **Linear Regression** | 0.7310 | 0.7665 | **0.5850** |
| KNN (k=3) | 0.7886 | 0.7366 | 0.1771 |
| KNN (k=5) | 0.7612 | 0.6878 | 0.3057 |
| KNN (k=7) | 0.6988 | 0.6368 | 0.3145 |

### Advertising (TV â†’ Sales)

| Modelo | RÂ² Dataset Completo | RÂ² Treino | RÂ² Teste |
|--------|---------------------|-----------|----------|
| **Linear Regression** | 0.6119 | 0.5736 | **0.6714** |
| KNN (k=3) | 0.7558 | 0.6634 | 0.5977 |
| KNN (k=5) | 0.6632 | 0.6228 | 0.6394 |
| KNN (k=7) | 0.6441 | 0.6015 | 0.6653 |

## VisualizaÃ§Ã£o dos Resultados

![ExercÃ­cio 3 - ComparaÃ§Ã£o RÂ² por Modelo](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/images/ex3_comparacao_r2.png)

![ExercÃ­cio 3 - Treino vs Teste](https://raw.githubusercontent.com/laerciosantos09/Senac-MachineLearning/main/Atividade%202/images/ex3_treino_teste.png)

---

## Respostas - ExercÃ­cio 3

### ComparaÃ§Ã£o: RegressÃ£o Linear vs KNN-Regressor

**RegressÃ£o Linear:**
- Modelo **paramÃ©trico e simples**
- Assume uma **relaÃ§Ã£o linear** entre as variÃ¡veis
- Menos propenso a overfitting em dados com relaÃ§Ã£o aproximadamente linear
- **Mais estÃ¡vel** entre treino e teste

**KNN (K-Nearest Neighbors):**
- Modelo **nÃ£o-paramÃ©trico e mais flexÃ­vel**
- Pode capturar **relaÃ§Ãµes nÃ£o-lineares**
- Mais propenso a **overfitting** (especialmente com k pequeno)
- O valor de K influencia o trade-off entre viÃ©s e variÃ¢ncia:
  - k pequeno â†’ baixo viÃ©s, alta variÃ¢ncia (overfitting)
  - k grande â†’ alto viÃ©s, baixa variÃ¢ncia (underfitting)

**ObservaÃ§Ãµes dos resultados:**
- Para dados com relaÃ§Ã£o aproximadamente linear (como estes), a **RegressÃ£o Linear geralmente tem desempenho igual ou melhor** que KNN no teste
- KNN com k=3 tem RÂ² alto no dataset completo (0.79 em Portland), mas **generaliza muito mal** (RÂ² = 0.18 no teste)
- A RegressÃ£o Linear Ã© mais consistente entre treino e teste

---

### Item 1. Comparar os resultados na partiÃ§Ã£o de treino e teste

**Resposta:**

**ObservaÃ§Ã£o geral:** O desempenho no **treino tende a ser igual ou melhor** que no teste, porque:
- O modelo foi **ajustado/otimizado** nos dados de treino
- Os dados de teste sÃ£o **"novos"** para o modelo

**AnÃ¡lise Portland:**

| Modelo | RÂ² Treino | RÂ² Teste | DiferenÃ§a | InterpretaÃ§Ã£o |
|--------|-----------|----------|-----------|---------------|
| LR | 0.77 | 0.59 | -0.18 | Boa generalizaÃ§Ã£o |
| KNN(k=3) | 0.74 | 0.18 | **-0.56** | Overfitting severo! |
| KNN(k=5) | 0.69 | 0.31 | -0.38 | Overfitting |
| KNN(k=7) | 0.64 | 0.31 | -0.33 | Overfitting |

**AnÃ¡lise Advertising:**

| Modelo | RÂ² Treino | RÂ² Teste | DiferenÃ§a | InterpretaÃ§Ã£o |
|--------|-----------|----------|-----------|---------------|
| LR | 0.57 | 0.67 | +0.10 | Excelente generalizaÃ§Ã£o |
| KNN(k=3) | 0.66 | 0.60 | -0.06 | Boa generalizaÃ§Ã£o |
| KNN(k=5) | 0.62 | 0.64 | +0.02 | Excelente generalizaÃ§Ã£o |
| KNN(k=7) | 0.60 | 0.67 | +0.07 | Excelente generalizaÃ§Ã£o |

**ConclusÃµes:**
- **Grande diferenÃ§a treino-teste indica overfitting** (modelo memorizou os dados de treino)
- No dataset Portland (menor, 47 amostras), o overfitting Ã© mais severo
- No dataset Advertising (maior, 200 amostras), os modelos generalizam melhor
- **RegressÃ£o Linear Ã© mais estÃ¡vel** e menos propensa a overfitting

---

### Item 2. Comparar desempenho com a regressÃ£o na qual nÃ£o foi feita a separaÃ§Ã£o entre treino e teste

#### Item 2.1. VocÃª acha que o desempenho deveria ser melhor ou pior nesse caso?

**Resposta:** O desempenho no **dataset completo** (sem separaÃ§Ã£o) tende a ser **"MELHOR" (RÂ² mais alto)**, mas isso Ã© uma **avaliaÃ§Ã£o ENGANOSA e OTIMISTA**.

**Por quÃª?**

1. **O modelo Ã© avaliado nos mesmos dados em que foi treinado**
   - Ã‰ como um aluno estudar apenas as respostas da prova e depois fazer a mesma prova
   - O modelo pode ter "decorado" os dados ao invÃ©s de aprender padrÃµes generalizÃ¡veis

2. **EvidÃªncia nos resultados:**
   - Portland LR: Dataset completo (0.73) > Teste (0.59)
   - Portland KNN(k=3): Dataset completo (0.79) >> Teste (0.18) â† **DiferenÃ§a enorme!**

3. **O RÂ² no dataset completo superestima a capacidade real do modelo**
   - NÃ£o reflete como o modelo se comportarÃ¡ com dados nunca vistos
   - Pode mascarar problemas de overfitting

#### Item 2.2. Ã‰ possÃ­vel dizer que os modelos treinados no dataset completo generalizam?

**Resposta:** **NÃƒO Ã© possÃ­vel afirmar com confianÃ§a** que modelos treinados no dataset completo generalizam.

**Motivos:**

1. **Sem separaÃ§Ã£o treino/teste, nÃ£o hÃ¡ como medir a capacidade de generalizaÃ§Ã£o**
   - GeneralizaÃ§Ã£o = capacidade de fazer boas previsÃµes em dados NOVOS
   - Se usamos todos os dados para treinar E avaliar, nunca vemos dados "novos"

2. **O modelo pode estar sofrendo overfitting sem que saibamos**
   - Exemplo: KNN(k=3) em Portland tem RÂ² = 0.79 no dataset completo
   - Mas quando testamos em dados novos: RÂ² = 0.18 (pÃ©ssimo!)
   - Sem o split, nunca descobrirÃ­amos esse problema

3. **A mÃ©trica no dataset completo Ã© ENVIESADA**
   - Sempre serÃ¡ igual ou melhor que a mÃ©trica real de generalizaÃ§Ã£o
   - DÃ¡ uma falsa sensaÃ§Ã£o de que o modelo Ã© bom

**ConclusÃ£o Final:**

> **A prÃ¡tica correta Ã© SEMPRE usar partiÃ§Ãµes de treino/teste (ou validaÃ§Ã£o cruzada) para avaliar modelos de forma honesta e estimar como eles se comportarÃ£o com dados nunca vistos antes.**

---

## ğŸ“Š Resumo Geral dos 3 ExercÃ­cios

| ExercÃ­cio | Dataset | Melhor Atributo/Modelo | ConclusÃ£o Principal |
|-----------|---------|------------------------|---------------------|
| 1 | Portland | **Tamanho** | RÂ² = 0.73 (3.7x melhor que Quartos) |
| 2 | Advertising | **TV** | RÂ² = 0.61 (TV > Radio > Newspaper) |
| 3 | Ambos | **Linear Regression** | Train/test split Ã© essencial para avaliar generalizaÃ§Ã£o |

## ğŸ¯ Aprendizados-Chave

1. **RÂ² alto** = modelo explica bem a variÃ¢ncia dos dados
2. **RSS baixo** = previsÃµes mais prÃ³ximas dos valores reais
3. **Sempre usar train/test split** para avaliaÃ§Ã£o honesta
4. **DiferenÃ§a grande treino-teste** = possÃ­vel overfitting
5. **Mais dados** = menos overfitting e melhor generalizaÃ§Ã£o
6. **RegressÃ£o Linear** Ã© mais estÃ¡vel que KNN para relaÃ§Ãµes lineares

---

## ğŸ› ï¸ Tecnologias Utilizadas

- Python 3
- Pandas
- NumPy
- Matplotlib
- Scikit-learn (LinearRegression, KNeighborsRegressor, train_test_split)

---

## ğŸ‘¤ Autor

**LaÃ©rcio Santos**

PÃ³s-graduaÃ§Ã£o em InteligÃªncia Artificial - Centro UniversitÃ¡rio SENAC
